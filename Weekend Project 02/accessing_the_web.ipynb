{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekend Workshop: Accessing data on the web\n",
    "\n",
    "---\n",
    "This workshop is to practice web scraping and dealing with data from APIs using Jupyter Notebooks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the web\n",
    "\n",
    "The Twitter API provides us with data conveniently in a JSON-structured format, but not all websites have as convenient ways for us to download data. If we still want to extract data from the site, we can access web pages directly using Python. \n",
    "\n",
    "When we access a web page directly, we'll replicate in Python what our web browser does when we visit a web page. We contact a website and load the web page, which is typically a HTML file. An HTML file is a text file that includes not only the content of a web page, but also instructions for the browser on how to display the content, for example in paragraphs, tables, bold font, links, and so on. \n",
    "\n",
    "When accessing the HTML text file in Python, we'll take advantage of this structure (e.g. identifiers for links) to extract the information we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the important problem of finding a good breakfast in the UK. [This article from the Guardian](https://www.theguardian.com/lifeandstyle/2017/jan/15/50-best-breakfasts-uk) purports to list the 50 best breakfasts in the UK.\n",
    "\n",
    "The list has interesting information, but in an unstructured form. If we wanted to remember these whenever we're visiting a different city, we'd probably want to store them in a file on our computer or online for easy access. \n",
    "\n",
    "We'll use Python to make this transformation.\n",
    "\n",
    "### HTML view\n",
    "\n",
    "The web page lists the restaurants, giving links, locations, and a short description of each. Let's look at how the undrlying HTML file looks like. When viewing a web page in a browser, we can typically do this with the shortcut `Ctrl + U`. This will open the HTML source in a new tab.\n",
    "\n",
    "The file is huge, with 3000 lines of text. We won't go into details of the HTML here, but instead look for the part in the file where the restaurants are presented. The first restaurant is in \"Lewannick\", so let's look for that in the source with `Ctrl + F`. We see the following result.\n",
    "\n",
    "```html\n",
    "<h2><strong><a href=\"http://www.coombesheadfarm.co.uk/\" data-link-name=\"in body link\" class=\"u-underline\">Coombeshead Farm</a></strong><strong>, Lewannick, Cornwall</strong><br></h2>\n",
    "<p>It might seem a bit bonkers to include an upmarket B&amp;B (from £90 a night) that doesn’t offer breakfast to non-residents (for the time being), but Coombeshead earns its place here because it does possibly the best breakfast in the UK, and certainly this writer’s favourite of 2016 anywhere.</p>\n",
    "```\n",
    "Compare this to the website as it is displayed in your browser and try to link the different parts together.\n",
    "\n",
    "\n",
    "Let's try to understand the first restaurant details from the HTML code. Above, the text \", Lewannick, Cornwall\" is packaged in between the HTML _tags_ `<strong>` and `</strong>`. The web browser uses HTML tags to display contents in a specific way, here in **bold** font. The tag `<strong>` is the opening tag which starts the emphasized text, and `</strong>` with a slash is the closing tag which ends the emphasis.\n",
    "\n",
    "\n",
    "Similarly, the text \"Coombeshead Farm\" is packaged in between the tags `<a>` and `</a>`:\n",
    "```html\n",
    "<a href=\"http://www.coombesheadfarm.co.uk/\" data-link-name=\"in body link\" class=\"u-underline\">Coombeshead Farm</a>\n",
    "```\n",
    "This is the HTML way of specifying a link to another page. The tag `<a href=\"http://www.coombesheadfarm.co.uk/\">` is the opening tag which creates the link to the restaurant's website. The tag `</a>` closes the tag: in between these, the text \"Coombeshead Farm\" is what gets displayed on the web page as the link text. Here, the tag has three _attributes_: `href` specifying the link address, and `data-link-name=\"in body link\"` and `class=\"u-underline\"`, which the browser uses to determine how the link is shown.\n",
    "\n",
    "There are many different HTML tags, which the web browser uses to display contents in a specific way. We will similarly use them to pick the data we'd like from the page.\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "We'll use the `requests` library to download the page HTML into Python. The code below fetches the page, and stores the result in `r`, which is a \"response\" object that the library creates. The object has a `text` attribute, which contains the HTML of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!DOCTYPE html>\\n<html id=\"js-context\" class=\"js-off is-not-modern id--signed-out\" lang=\"en\" data-page-path=\"/lifeandstyle/2017/jan/15/50-best-breakfasts-uk\">\\n<head>\\n<title>The 50 best breakfast places in the UK | Food | The Guardian</title>\\n<meta charset=\"utf-8\">\\n<meta name=\"description\" content=\"Breakfasts in Britain are among the best in the world. Here – region by region – are the very finest places to start your day\"/>\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"/>\\n<meta name=\"forma'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://www.theguardian.com/lifeandstyle/2017/jan/15/50-best-breakfasts-uk\")\n",
    "r.text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll parse the HTML using the `BeautifulSoup 4` library. Let's import it and parse the text. The code below creates a `soup` object that the Beautiful Soup library works with. Similarly to a web browser, Beautiful Soup takes advantage of the tag structure of the web page, not to display it, but to parse for the information that we'd like to store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "soup = BeautifulSoup(r.text, 'lxml')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting restaurants\n",
    "\n",
    "We'd like to get all 50 restaurants' names, locations, and websites. Let's take another look at the HTML source.\n",
    "\n",
    "```html\n",
    "<h2><strong><a href=\"http://www.coombesheadfarm.co.uk/\" data-link-name=\"in body link\" class=\"u-underline\">Coombeshead Farm</a></strong><strong>, Lewannick, Cornwall</strong><br></h2>\n",
    "<p>It might seem a bit bonkers to include an upmarket B&amp;B (from £90 a night) that doesn’t offer breakfast to non-residents (for the time being), but Coombeshead earns its place here because it does possibly the best breakfast in the UK, and certainly this writer’s favourite of 2016 anywhere.</p>\n",
    "```\n",
    "\n",
    "It looks like the structure of the data we'd like is roughly the following.\n",
    "```html\n",
    "<h2><strong><a href=\"WEBPAGE LINK\" data-link-name=\"in body link\" class=\"u-underline\">RESTAURANT NAME</a></strong><strong>, LOCATION</strong><br></h2>\n",
    "```\n",
    "There's an outer `<h2>` tag which specifies a header, a `<strong>` tag and an `<a>` tag fpr the link and the name, and another `<strong>` tag for the location.\n",
    "\n",
    "We'd like to pick the three capitalized parts for all restaurants. We can search for tags in Beautiful Soup as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2><strong><a class=\"u-underline\" data-link-name=\"in body link\" href=\"http://www.coombesheadfarm.co.uk/\">Coombeshead Farm</a></strong><strong>, Lewannick, Cornwall</strong><br/></h2>, <h2><a class=\"u-underline\" data-link-name=\"in body link\" href=\"http://cafealfresco.co.uk/page/eat\"><strong>Café Alf Resco</strong></a><strong>, Dartmouth, Devon</strong></h2>]\n"
     ]
    }
   ],
   "source": [
    "results = soup.find_all('h2') # find all h2 tags\n",
    "print(results[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can extract the information we want from each restaurant. We can take the first result we found, and apply Beautiful Soup's find method to it again to find (the first) link. The link will have the _attribute_ text and contain the actual link as `link['href']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coombeshead Farm http://www.coombesheadfarm.co.uk/\n",
      "Lewannick, Cornwall\n"
     ]
    }
   ],
   "source": [
    "# Find link in first result\n",
    "link = results[0].find('a') # find link\n",
    "name = link.text # get text\n",
    "url = link['href'] # get link address\n",
    "print(name, url)\n",
    "\n",
    "# Find the location\n",
    "location = results[0].find_all('strong')[1].text\n",
    "location = location.lstrip(' ,') # get rid of leading comma and space\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping is messy\n",
    "\n",
    "Now try to write a loop that repeats this for all the restaurants. Store the results in a list containing dictionary entries as follows:\n",
    "```python\n",
    "[{'Restaurant':name, 'Web page':url, 'Location':location}]\n",
    "```\n",
    "\n",
    "At some point you will run into trouble. This is because we have not just picked all restaurants, but other things in the article that also have the `<h2>` tag. Some of the results will thus not contain the information we want, and we need to prune them  further. Try to work your loop around this, and other issues you'll run into, to pick the 50 restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "result_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your results, you can use the following code to write the dictionary into a csv file with the `csv` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# File column names\n",
    "csv_columns = ['Location','Restaurant','Web page']\n",
    "\n",
    "with open('best_breakfast_guardian.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "    writer.writeheader() # header row\n",
    "    for rest in result_list: # rest of rows\n",
    "        writer.writerow(rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we also wanted to store the description of each restaurant? One approach to do so is to use the hierarchical structure of the file's HTML tags with Beautiful Soup. We say that the tags at the same level in the hierarchy as our current tag are _siblings_, while those above (nesting the current tag) are _parents_ and those below (inside the current tag) are _children_.  \n",
    "\n",
    "Inspecting the HTML, we see that the tags between two `<h2>` tags are `<p>` tags for paragraphs. Starting from a `<h2>` tag, we can loop through the paragraphs with the `next_sibling` attribute until we run into the next `<h2>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p>It might seem a bit bonkers to include an upmarket B&amp;B (from £90 a night) that doesn’t offer breakfast to non-residents (for the time being), but Coombeshead earns its place here because it does possibly the best breakfast in the UK, and certainly this writer’s favourite of 2016 anywhere.</p>\n",
      "\n",
      "\n",
      "<p>The love child of two celebrated chefs, <a class=\"u-underline\" data-link-name=\"in body link\" href=\"http://aprilbloomfield.com/\">April Bloomfield</a> (of The Spotted Pig and The Breslin in New York) and Tom Adams (of <a class=\"u-underline\" data-link-name=\"in body link\" href=\"http://www.pittcue.co.uk/\">Pittcue in London</a>), this idyllic Cornish farmhouse, set in 60-plus acres of picture-postcard meadow and woodland, serves up an equally idyllic breakfast. Adams and co go the extra mile over the most important meal of the day: everything is homegrown, made on site or sourced as locally as possible.</p>\n",
      "\n",
      "\n",
      "<p>From the granola, bircher muesli, honey and on-trend kombucha (for those who like that kind of thing) to the outrageously brilliant cooked offering – which comprises a thick slice of home-cured belly bacon, a pillow of scrambled eggs (most likely laid that morning by the chooks scratching away in the garden), proper sourdough toast (that is, packing a real crunch and smothered in home-churned butter – yes, really) and a homemade hog’s pudding that I still dream about – I can’t think of many better ways to start the day. Actually, scratch that: I can’t think of many places I’d rather be full stop.</p>\n",
      "\n",
      "\n",
      "<p>The dinners (Thursday to Sunday nights) are something else, too, and you don’t have to stay over to tuck into those. <br/><strong>What to order:</strong> Everything.</p>\n",
      "\n",
      "\n",
      "Here's the full text:\n",
      "\n",
      "It might seem a bit bonkers to include an upmarket B&B (from £90 a night) that doesn’t offer breakfast to non-residents (for the time being), but Coombeshead earns its place here because it does possibly the best breakfast in the UK, and certainly this writer’s favourite of 2016 anywhere. The love child of two celebrated chefs, April Bloomfield (of The Spotted Pig and The Breslin in New York) and Tom Adams (of Pittcue in London), this idyllic Cornish farmhouse, set in 60-plus acres of picture-postcard meadow and woodland, serves up an equally idyllic breakfast. Adams and co go the extra mile over the most important meal of the day: everything is homegrown, made on site or sourced as locally as possible. From the granola, bircher muesli, honey and on-trend kombucha (for those who like that kind of thing) to the outrageously brilliant cooked offering – which comprises a thick slice of home-cured belly bacon, a pillow of scrambled eggs (most likely laid that morning by the chooks scratching away in the garden), proper sourdough toast (that is, packing a real crunch and smothered in home-churned butter – yes, really) and a homemade hog’s pudding that I still dream about – I can’t think of many better ways to start the day. Actually, scratch that: I can’t think of many places I’d rather be full stop. The dinners (Thursday to Sunday nights) are something else, too, and you don’t have to stay over to tuck into those. What to order: Everything. \n"
     ]
    }
   ],
   "source": [
    "current = results[0]\n",
    "\n",
    "text = ''\n",
    "# Loop until find next restaurant, ie h2 tag\n",
    "while current.next_sibling.name != 'h2':\n",
    "    print(current.next_sibling) # Either <p> or a new line\n",
    "    current = current.next_sibling\n",
    "    if current.name is not None: # Only get the paragraph text\n",
    "        text += current.text + ' ' # Add a space between paragraphs\n",
    "print('Here\\'s the full text:\\n')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the web\n",
    "\n",
    "As you've seen with the example, web scraping can easily get messy. The less structured the data that we're trying to gather is, the more tricky it is to parse it. In practice, web scraping works best for \n",
    "* Structured pages. The page we've just scraped is a text article with some header structure. Scraping data from tables or other more structured forms is often much easier. \n",
    "* Static pages. Accessing dynamic content (eg JavaScript) is often impossible through the standard HTML approach we have used. Alternative ways exist, but require more work.\n",
    "\n",
    "Compared to downloading a file or using an API, web scraping is a fragile way to access a site. The HTML page could be changed, breaking your scraper, whereas APIs are often well maintained and robust. \n",
    "\n",
    "You'll have noticed that it would be very easy to crawl through a lot of pages on a site very quickly by looping requests. This could be on a news website, or for example looking for business analytics positions on an online jobs platform. Before you do this, note that many websites don't like crawlers: The Guardian's business model, for instance, depends on ad revenues, so they don't like their content being automatically accessed. Here we've downloaded just one page, but if you ran a big scraping operation on them, they might ban you (and your flatmates). They do have an [API](http://open-platform.theguardian.com/access/) for accessing content.\n",
    "\n",
    "In brief, scraping can be a powerful tool, but if there's an alternative way to get the data you need, don't scrape manually. If you do scrape data, be nice to the website and follow their terms of access.\n",
    "\n",
    "Here are some further resources on scraping:\n",
    "* [The Beautiful Soup documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) is very well written\n",
    "* [A success story with scraping](https://www.wired.com/2014/01/how-to-hack-okcupid/all/)\n",
    "* [A nice and well-documented application on the NY Times website](http://www.dataschool.io/python-web-scraping-of-president-trumps-lies/)\n",
    "* [Web data collection tasks from Stanford's Computational Journalism lab](https://github.com/stanfordjournalism/search-script-scrape), mostly through various US government APIs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
